---
title: Analysing useR!2017 schedule data
author: Emil Hvitfeldt
date: '2017-07-20'
slug: analysing-user-2017-schedule-data
categories: []
tags: []
type: "blog"
showonlyimage: false
weight: 1
image: "/img/blog/analysing-user-2017-schedule-data/cover.png"
description: "Are we seeing the same thing? Which talks were attended using useR!2017"
output:
  blogdown::html_page:
    toc: true
---

<script src="/rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<script src="/rmarkdown-libs/plotly-binding/plotly.js"></script>
<script src="/rmarkdown-libs/typedarray/typedarray.min.js"></script>
<script src="/rmarkdown-libs/jquery/jquery.min.js"></script>
<link href="/rmarkdown-libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="/rmarkdown-libs/crosstalk/js/crosstalk.min.js"></script>
<link href="/rmarkdown-libs/plotly-htmlwidgets-css/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="/rmarkdown-libs/plotly-main/plotly-latest.min.js"></script>
<link href="/rmarkdown-libs/vis/vis.css" rel="stylesheet" />
<script src="/rmarkdown-libs/vis/vis.min.js"></script>
<script src="/rmarkdown-libs/visNetwork-binding/visNetwork.js"></script>

<div id="TOC">
<ul>
<li><a href="#packages">Packages</a></li>
<li><a href="#web-scraping">Web scraping</a></li>
<li><a href="#visualizations">visualizations</a><ul>
<li><a href="#network-graph">Network graph</a></li>
</ul></li>
</ul>
</div>

<p><em>This code have been lightly revised to make sure it works as of 2018-12-16.</em></p>
<p>After attending useR!2017 for the first time, which great pleasure and new connections made. I decided to see if I could extract some of the information available in the public schedule. So as with my last post I’ll do a bit of scraping followed by a few visualizations.</p>
<div id="packages" class="section level2">
<h2>Packages</h2>
<pre class="r"><code>library(tidyverse)
library(utils)
library(plotly)
library(ltm)
require(visNetwork)</code></pre>
</div>
<div id="web-scraping" class="section level2">
<h2>Web scraping</h2>
<p>I found this task easiest with the help of <code>purrr:map()</code>. First we find the full schedules at the following links</p>
<p><a href="https://user2017.sched.com/2017-07-04/overview" class="uri">https://user2017.sched.com/2017-07-04/overview</a> (Tuesday)<br />
<a href="https://user2017.sched.com/2017-07-05/overview" class="uri">https://user2017.sched.com/2017-07-05/overview</a> (Wednesday)<br />
<a href="https://user2017.sched.com/2017-07-06/overview" class="uri">https://user2017.sched.com/2017-07-06/overview</a> (Thursday)<br />
<a href="https://user2017.sched.com/2017-07-07/overview" class="uri">https://user2017.sched.com/2017-07-07/overview</a> (Friday)</p>
<p>then we read the entire page into a tibble along with a <em>day</em> variable.</p>
<pre class="r"><code>day &lt;- c(&quot;Tuesday&quot;, &quot;Wednesday&quot;, &quot;Thursday&quot;, &quot;Friday&quot;)
link &lt;- paste0(&quot;https://user2017.sched.com/2017-07-0&quot;, 4:7, &quot;/overview&quot;, sep = &quot;&quot;)

event0 &lt;- map2_df(link, day,
                  ~ tibble(text = readLines(.x),
                           day = .y))</code></pre>
<p>then with the help of <code>stringr</code> we extract the desired information from the document, following the idiom that “multiple simple regex are better then one complicated one”. I also filtered out most non-talk events.</p>
<pre class="r"><code>events &lt;- event0 %&gt;% 
  filter(str_detect(text, &quot;&lt;span class=&#39;&quot;) | str_detect(text, &quot;&lt;/h3&gt;&quot;),
         !str_detect(text, &quot;REGISTRATION&quot;),
         !str_detect(text, &quot;COFFEE BREAK&quot;),
         !str_detect(text, &quot;LUNCH&quot;),
         !str_detect(text, &quot;WELCOME&quot;),
         !str_detect(text, &quot;Poster&quot;),
         !str_detect(text, &quot;RIOT SESSION&quot;),
         !str_detect(text, &quot;Buses&quot;),
         !str_detect(text, &quot;Dinner&quot;),
         !str_detect(text, &quot;CLOSING&quot;)) %&gt;%
  mutate(time = str_extract(text, &quot;&lt;h3&gt;.{1,7}&quot;), # time
         time = str_replace(time, &quot;&lt;h3&gt; *&quot;, &quot;&quot;),
         id = str_extract(text, &quot;id=&#39;\\S{32}&quot;), # id
         id = str_replace(id, &quot;id=&#39;&quot;, &quot;&quot;),
         name = str_extract(text, str_c(id, &quot;.*&quot;)), # name
         name = str_replace(name, str_c(id, &quot;&#39;&gt;&quot;), &quot;&quot;),
         name = str_extract(name, &quot;^.*(?=( &lt;span))&quot;),
         room = str_extract(text, &#39;vs&quot;&gt;(.*?)&lt;&#39;),
         room = str_replace(room, &#39;vs&quot;&gt;&#39;, &quot;&quot;),
         room = str_replace(room, &#39;&lt;&#39;,&quot;&quot;)) %&gt;% # room
  fill(time) %&gt;%
  filter(!str_detect(text, &quot;&lt;h3&gt;&quot;)) %&gt;%
  dplyr::select(-text)</code></pre>
<p>lets take a look at what we have by now just to see that we have what we want.</p>
<pre class="r"><code>head(events)</code></pre>
<pre><code>## # A tibble: 6 x 5
##   day     time   id                  name                            room  
##   &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;               &lt;chr&gt;                           &lt;chr&gt; 
## 1 Tuesday 9:30am 893eab219225a09907… Data Carpentry: Open and Repro… 2.02  
## 2 Tuesday 9:30am 30c0eebdc887f3ad3a… Dose-response analysis using R  4.02  
## 3 Tuesday 9:30am 57ce234e5ce9082da3… Geospatial visualization using… 4.03  
## 4 Tuesday 9:30am 95b110146486b0a5f8… Introduction to Bayesian infer… 2.01  
## 5 Tuesday 9:30am 7294f7df20ab1a7c37… Introduction to parallel compu… 3.01  
## 6 Tuesday 9:30am f15703fe51e89294f2… Rcpp: From Simple Examples to … PLENA…</code></pre>
<p>Now that we have all the information about the different events we can scrape every event page to find its attendees. This following chuck of code might seem a little hard at first, it helps to notice that there is a second tibble inside the big tibble.</p>
<pre class="r"><code>people &lt;- map_df(events$id,
       ~ tibble(attendee = tibble(text = readLines(
         str_c(&quot;https://user2017.sched.com/event-goers/&quot;, .x))) %&gt;%
                filter(str_detect(text, &quot; +&lt;li&gt;&lt;a href=&quot;)) %&gt;% 
                .$text %&gt;%
                str_split(., &quot;li&gt;&lt;li&quot;) %&gt;% 
                unlist(),
       id = .x) %&gt;%
  mutate(attendee = str_replace(attendee, &quot;(.*?)title=\&quot;&quot;, &quot;&quot;),
         attendee = str_replace(attendee, &quot;\&quot;&gt;&lt;(.*)&quot;, &quot;&quot;)) %&gt;%
  filter(!str_detect(attendee, &quot;venue&quot;),
         !str_detect(attendee, &quot;Private&quot;)))</code></pre>
<p>lets again take a look at what we have by now just to see that we have what we want.</p>
<pre class="r"><code>head(people)</code></pre>
<pre><code>## # A tibble: 6 x 2
##   attendee                                           id                    
##   &lt;chr&gt;                                              &lt;chr&gt;                 
## 1 &quot;              &lt;li&gt;&lt;a href=\&quot;/\&quot;&gt;Schedule&lt;/a&gt;&lt;/li… 893eab219225a09907704…
## 2 &quot;                                                … 893eab219225a09907704…
## 3 Marc Trunjer Kusk Nielsen                          893eab219225a09907704…
## 4 lvaudor                                            893eab219225a09907704…
## 5 Alan Ponce                                         893eab219225a09907704…
## 6 bpiccolo                                           893eab219225a09907704…</code></pre>
</div>
<div id="visualizations" class="section level2">
<h2>visualizations</h2>
<p>With a data set with this many possibilities the options are quite few, so here I’ll just list a few of the ones I found handy. So first we just do a simple bubble plot, this will be done with <code>left_join</code>’s and <code>count</code> and piped straight into <code>ggplot</code>.</p>
<pre class="r"><code>left_join(events, people, by = &quot;id&quot;) %&gt;%
  count(id) %&gt;%
  left_join(events, by = &quot;id&quot;) %&gt;%
  filter(day == &quot;Friday&quot;) %&gt;%
  ggplot(aes(time, room, size = n)) +
  geom_point() +
  theme_bw() +
  scale_size(range = c(5, 20)) +
  labs(title = &quot;useR!2017 Friday schedule&quot;,
       x = &quot;&quot;)</code></pre>
<p><img src="/blog/2017-07-20-analysing-user-2017-schedule-data_files/figure-html/unnamed-chunk-7-1.png" width="700px" style="display: block; margin: auto;" /></p>
<p>Since both our <code>room</code> and <code>time</code> were simply character vectors, the ordering is not right. This can be fixed by setting the levels correctly. Here I have the ordered vectored for both <code>room</code> and <code>time</code>.</p>
<pre class="r"><code>time_levels &lt;- c(&quot;9:15am&quot;, &quot;9:30am&quot;, &quot;11:00am&quot;, &quot;11:18am&quot;, &quot;11:30am&quot;, &quot;11:36am&quot;,
                 &quot;11:54am&quot;, &quot;12:12pm&quot;, &quot;1:15pm&quot;, &quot;1:30pm&quot;, &quot;1:48pm&quot;, &quot;2:00pm&quot;, 
                 &quot;2:06pm&quot;, &quot;2:24pm&quot;, &quot;2:42pm&quot;, &quot;3:30pm&quot;, &quot;3:45pm&quot;, &quot;4:00pm&quot;, 
                 &quot;4:45pm&quot;, &quot;4:55pm&quot;, &quot;5:00pm&quot;, &quot;5:05pm&quot;, &quot;5:30pm&quot;, &quot;5:35pm&quot;, 
                 &quot;5:40pm&quot;, &quot;5:45pm&quot;, &quot;5:50pm&quot;, &quot;5:55pm&quot;, &quot;6:00pm&quot;, &quot;6:05pm&quot;, 
                 &quot;6:10pm&quot;, &quot;6:15pm&quot;, &quot;6:20pm&quot;, &quot;7:00pm&quot;)
room_levels &lt;- c(&quot;PLENARY&quot;, &quot;2.01&quot;, &quot;2.02&quot;, &quot;3.01&quot;, &quot;3.02&quot;, &quot;4.01&quot;, &quot;4.02&quot;)</code></pre>
<p>and we deal with it with a single mutate like so</p>
<pre class="r"><code>left_join(events, people, by = &quot;id&quot;) %&gt;%
  count(id) %&gt;%
  left_join(events, by = &quot;id&quot;) %&gt;%
  mutate(time = factor(time, time_levels),
         room = factor(room, room_levels)) %&gt;%
  filter(day == &quot;Friday&quot;) %&gt;%
  ggplot(aes(time, room, size = n)) +
  geom_point() +
  theme_bw() +
  scale_size(range = c(5, 20)) +
  labs(title = &quot;useR!2017 Friday schedule&quot;,
       x = &quot;&quot;)</code></pre>
<p><img src="/blog/2017-07-20-analysing-user-2017-schedule-data_files/figure-html/unnamed-chunk-9-1.png" width="700px" style="display: block; margin: auto;" /></p>
<p>another way to visualize it would be to use a stacked bar chart like so</p>
<pre class="r"><code>p &lt;- left_join(events, people, by = &quot;id&quot;) %&gt;%
  count(id) %&gt;%
  left_join(events, by = &quot;id&quot;) %&gt;%
  filter(day == &quot;Thursday&quot;) %&gt;%
  mutate(time = factor(time, time_levels),
         room = factor(room, rev(room_levels))) %&gt;%
  ggplot(aes(time, fill = room, text = name)) +
  geom_bar(aes(weight = n)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = &quot;useR!2017 Thursday schedule&quot;,
       x = &quot;&quot;)
p</code></pre>
<p><img src="/blog/2017-07-20-analysing-user-2017-schedule-data_files/figure-html/unnamed-chunk-10-1.png" width="700px" style="display: block; margin: auto;" /></p>
<p>or with a bit of interactivity <code>plotly::ggplotly</code> can be used so that is possible to hover over each event to see name and size.</p>
<pre class="r"><code>ggplotly(p, tooltip = c(&quot;n&quot;, &quot;name&quot;), width = 900, height = 555)</code></pre>
<div id="htmlwidget-1" style="width:900px;height:555px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"data":[{"orientation":"v","width":[0.9,0.9,0.9,0.9,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999],"base":[744,474,515,612,699,665,678,574,491,453,343,456,302,483,394,336,268,346,343,224],"x":[3,4,5,6,8,9,10,11,12,19,20,21,22,23,24,25,26,27,28,29],"y":[62,261,345,202,91,298,76,120,153,90,48,224,100,58,96,134,169,119,130,80],"text":["n:  62<br />moodler: A new R package to easily fetch data from Moodle","n: 261<br />Can you keep a secret?","n: 345<br />Scraping data with rvest and purrr","n: 202<br />jug: Building Web APIs for R","n:  91<br />Interactive graphs for blind and print disabled people","n: 298<br />Package ggiraph: a ggplot2 Extension for Interactive Graphics","n:  76<br />Visual funnel plot inference for meta-analysis","n: 120<br />mapedit - interactive manipulation of spatial objects","n: 153<br />Exploring and presenting maps with **tmap**","n:  90<br />R in a small-sized bank's risk management","n:  48<br />**eventstudies**: An *R* package for conducting event studies and a platform for methodological research on event studies","n: 224<br />Automatic Machine Learning in R","n: 100<br />R in a Pharmaceutical Company","n:  58<br />Using R to Analyze Healthcare Cost of Older Patients Using Personal Emergency Response Service","n:  96<br />Statistics hitting the business front line","n: 134<br />An example of Shiny tool at Nestlé R&D, an enabler to guide product developers in designing gluten free biscuits","n: 169<br />Using R for optimal beer recipe selection","n: 119<br />Candy Crush R Saga","n: 130<br />Gamifyr: Transforming Machine Learning Tasks into Games with Shiny","n:  80<br />Ultra-Fast Data Mining With The R-KDB+ Interface"],"type":"bar","marker":{"autocolorscale":false,"color":"rgba(248,118,109,1)","line":{"width":1.88976377952756,"color":"transparent"}},"name":"4.02","legendgroup":"4.02","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"orientation":"v","width":[0.9,0.9,0.9,0.9,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999],"base":[632,419,462,569,404,295,421,274,416,358,309,191,321,302],"x":[3,4,5,6,19,20,21,22,23,24,25,26,27,28],"y":[112,55,53,43,49,48,35,28,67,36,27,77,25,41],"text":["n: 112<br />Bayesian social network analysis with Bergm","n:  55<br />difNLR: Detection of potentional gender/minority bias with extensions of logistic regression","n:  53<br />**BradleyTerryScalable**: Ranking items scalably with the Bradley-Terry model","n:  43<br />IRT test equating with the R package equateIRT","n:  49<br />DNA methylation-based classification of human central nervous system tumors","n:  48<br />Multivariate statistics for PAT data analysis: short overview of existing R packages and methods","n:  35<br />R in research on microbial mutation rates","n:  28<br />Plasmid Profiler: Comparative Analysis of Plasmid Content in WGS Data","n:  67<br />Application of R and Shiny in multiomics understanding of blood cancer biology and drug response","n:  36<br />Simulate phenotype(s) with epistatic interactions","n:  27<br />Introducing the DynNom package for the generation of dynamic nomograms","n:  77<br />Graduate from plot to ggplot2: Using R to visualize the story of Ebola survivors in the PREVAIL III Ebola Natural History Study","n:  25<br />**BivRegBLS**, a new *R* package: Tolerance Intervals and Errors-in-Variables Regressions in Method Comparison Studies","n:  41<br />What is missing from the meta-analysis landscape?"],"type":"bar","marker":{"autocolorscale":false,"color":"rgba(196,154,0,1)","line":{"width":1.88976377952756,"color":"transparent"}},"name":"4.01","legendgroup":"4.01","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"orientation":"v","width":[0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999],"base":[515,413,511,344,405,253,178,272,220,323,273,261,147,229,220],"x":[8,9,10,11,12,19,20,21,22,23,24,25,26,27,28],"y":[184,252,167,230,86,151,117,149,54,93,85,48,44,92,82],"text":["n: 184<br />ReinforcementLearning: A package for replicating human behavior in R","n: 252<br />Deep Learning for Natural Language Processing in R","n: 167<br />R4ML: A Scalable R for Machine Learning","n: 230<br />Computer Vision and Image Recognition algorithms for R users","n:  86<br />Depth and depth-based classification with R package **ddalpha**","n: 151<br />R Blogging with blogdown and GitHub","n: 117<br />**redmineR** and the story of automating *useR!2017* abstract review process","n: 149<br />The current state of naming conventions in R","n:  54<br />An Introduction to the r2anki-package","n:  93<br />rOpenGov: community project for open government data","n:  85<br />R.gov: making R work for government","n:  48<br />nsoAPI - retrieving data from National Statistical Offices with R","n:  44<br />Jurimetrics: quantitative analysis of judicial decisions using R","n:  92<br />Shiny Apps for Maths and Stats Exercises","n:  82<br />Working with R when internet is not reliable"],"type":"bar","marker":{"autocolorscale":false,"color":"rgba(83,180,0,1)","line":{"width":1.88976377952756,"color":"transparent"}},"name":"3.02","legendgroup":"3.02","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"orientation":"v","width":[0.9,0.9,0.9,0.9,0.9,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999],"base":[594,368,409,480,545,443,281,363,223,243,188,107,158,144,197,196,134,97,151,155,88],"x":[3,4,5,6,7,8,9,10,11,12,19,20,21,22,23,24,25,26,27,28,29],"y":[38,51,53,89,107,72,132,148,121,162,65,71,114,76,126,77,127,50,78,65,136],"text":["n:  38<br />**rags2ridges**: A One-Stop-Go for Network Modeling of Precision Matrices","n:  51<br />Various Versatile Variances: An Object-Oriented Implementation of Clustered Covariances in *R*","n:  53<br />factorMerger: a set of tools to support results from post hoc testing","n:  89<br />Estimating the Parameters of a Continuous-Time Markov Chain from Discrete-Time Data with ctmcd","n: 107<br />MCMC Output Analysis Using R package mcmcse","n:  72<br />An Efficient Algorithm for Solving Large Fixed Effects OLS Problems with Clustered Standard Error Estimation","n: 132<br />R Package glmm: Likelihood-Based Inference for Generalized Linear Mixed Models","n: 148<br />**countreg**: Tools for count data regression","n: 121<br />How to Use (R)Stan to Estimate Models in External R Packages","n: 162<br />brms: Bayesian Multilevel Models using Stan","n:  65<br />The cutpointr package: Improved and tidy estimation of optimal cutpoints","n:  71<br />Preparing Datetime Data with Padr","n: 114<br />R in Minecraft","n:  76<br />Digital Signal Processing with R","n: 126<br />Data Analysis Using Hierarchical Generalized Linear Models with R","n:  77<br />The R package bigstatsr: Memory- and Computation-Efficient Statistical Tools for Big Matrices","n: 127<br />Advanced R Solutions -- A Bookdown Project","n:  50<br />Functional Input Validation with valaddin","n:  78<br />ROI - R Optimization Infrastructure","n:  65<br />simmer: Discrete-Event Simulation for R","n: 136<br />Data Error! But where?"],"type":"bar","marker":{"autocolorscale":false,"color":"rgba(0,192,148,1)","line":{"width":1.88976377952756,"color":"transparent"}},"name":"3.01","legendgroup":"3.01","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"orientation":"v","width":[0.9,0.9,0.9,0.9,0.9,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999],"base":[522,157,234,257,274,356,230,337,194,58,28,22,24,39,46,50,30,24,35],"x":[3,4,5,6,7,8,9,10,11,19,20,21,22,23,24,25,26,27,28],"y":[72,211,175,223,271,87,51,26,29,130,79,136,120,158,150,84,67,127,120],"text":["n:  72<br />Hosting Data Packages via `drat`: A Case Study with Hurricane Exposure Data","n: 211<br />Clouds, Containers and R, towards a global hub for reproducible and collaborative data science","n: 175<br />codebookr: Codebooks in *R*","n: 223<br />Show me the errors you didn't look for","n: 271<br />Automatically archiving reproducible studies with Docker","n:  87<br />The **renjin** package: Painless Just-in-time Compilation for High Performance R","n:  51<br />An LLVM-based Compiler Toolkit for R","n:  26<br />Performance Benchmarking of the R Programming Environment on Knight's Landing","n:  29<br />*GNU R* on a Programmable Logic Controller (PLC) in an Embedded-Linux Environment","n: 130<br />R and Tableau Integration: A Case approach","n:  79<br />The dataCompareR package","n: 136<br />Use of templates within an R package to create a (semi-)automated analysis workflow and/or report","n: 120<br />graphiT: an interactive, user-friendly tool to produce graphics based on the grammar of graphics' principles","n: 158<br />**heatmaply**: an *R* package for creating interactive cluster heatmaps","n: 150<br />Plot Colour Helper – Finally an easy way to pick colours for your R plots!","n:  84<br />bsplus: Using Twitter Bootstrap to extend your Shiny app","n:  67<br />TAGS - Table Assorting Guided System: an HTML widget to create multiple tables from Excel spreadsheets","n: 127<br />Object-oriented markdown in R to facilitate collaboration","n: 120<br />Strategies for Reproducible Research with Packrat"],"type":"bar","marker":{"autocolorscale":false,"color":"rgba(0,182,235,1)","line":{"width":1.88976377952756,"color":"transparent"}},"name":"2.02","legendgroup":"2.02","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"orientation":"v","width":[0.9,0.9,0.9,0.9,0.9,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999],"base":[486,74,177,167,198,115,118,133,66,150,0,0,0,0,0,0,0,0,0,0,0],"x":[3,4,5,6,7,8,9,10,11,12,19,20,21,22,23,24,25,26,27,28,29],"y":[36,83,57,90,76,241,112,204,128,93,58,28,22,24,39,46,50,30,24,35,88],"text":["n:  36<br />Using the alphabetr package to determine paired T cell receptor sequences","n:  83<br />Differentiation of brain tumor tissue using hierarchical non-negative matrix factorization","n:  57<br />Biosignature-Based Drug Design: from high dimensional data to business impact","n:  90<br />Interactive and Reproducible Research for RNA Sequencing Analysis","n:  76<br />Stochastic Gradient Descent Log-Likelihood Estimation in the Cox Proportional Hazards Model with Applications to The Cancer Genome Atlas Data","n: 241<br />R-based computing with big data on disk","n: 112<br />Daff: diff, patch and merge for data.frames","n: 204<br />odbc - A modern database interface","n: 128<br />Improving DBI","n:  93<br />*implyr**: A **dplyr** Backend for a Apache Impala","n:  58<br />rdwd – manage German weather observations","n:  28<br />eseis – A toolbox to weld seismologic and geomorphic data analysis","n:  22<br />An R Decision Support Framework for the Identification of BMP in Catchments","n:  24<br />Reproducible research in computational subsurface hydrology - First steps in R with RMODFLOW and RMT3DMS","n:  39<br />Using an R package as platform for harmonized cleaning of data from RTI MicroPEM air quality sensors","n:  46<br />map data from **naturalearth** : aiming for sustainability through specialisation and **rOpenSci**","n:  50<br />OpenSpat, spread the spatial world","n:  30<br />smires -- Calculating Hydrological Metrics for Univariate Time Series","n:  24<br />minimalRSD and FMC: R packages to construct cost efficient experimental designs","n:  35<br />ICtest: Estimating the Number of Interesting Components","n:  88<br />Better Confidence Intervals for Quantiles"],"type":"bar","marker":{"autocolorscale":false,"color":"rgba(165,138,255,1)","line":{"width":1.88976377952756,"color":"transparent"}},"name":"2.01","legendgroup":"2.01","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"orientation":"v","width":[0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999],"base":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"x":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18],"y":[276,450,486,74,177,167,198,115,118,133,66,150,330,527,37,36,31,33],"text":["n: 276<br />Sponsor Talk Open Analytics","n: 450<br />KEYNOTE: Dose-response analysis: considering dose both as qualitative factor and quantitative covariate- using R*","n: 486<br />Show Me Your Model: tools for visualisation of statistical models","n:  74<br />Quantitative fisheries advice using R and FLR","n: 177<br />*jamovi*: a spreadsheet for R","n: 167<br />The growing popularity of R in data journalism","n: 198<br />FFTrees: An R package to create, visualise and use fast and frugal decision trees","n: 115<br />Community-based learning and knowledge sharing","n: 118<br />Data Carpentry: Teaching Reproducible Data Driven Discovery","n: 133<br />Statistics in Action with R: an educative platform","n:  66<br />A quasi-experiment for the influence of the user interface on the acceptance of R","n: 150<br />The analysis of R learning styles with R","n: 330<br />Sponsor Talk Rstudio","n: 527<br />KEYNOTE: Parallel Computation in R:  What We Want, and How We (Might) Get It","n:  37<br />SPONSOR TALK EODA","n:  36<br />SPONSOR TALK ORACLE","n:  31<br />SPONSOR TALK MANGO SOLUTIONS","n:  33<br />SPONSOR TALK ALTERYX"],"type":"bar","marker":{"autocolorscale":false,"color":"rgba(251,97,215,1)","line":{"width":1.88976377952756,"color":"transparent"}},"name":"PLENARY","legendgroup":"PLENARY","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":45.3817104776009,"r":7.30593607305936,"b":37.8531000277654,"l":48.9497716894977},"plot_bgcolor":"rgba(255,255,255,1)","paper_bgcolor":"rgba(255,255,255,1)","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"title":"useR!2017 Thursday schedule","titlefont":{"color":"rgba(0,0,0,1)","family":"","size":17.5342465753425},"xaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[0.4,29.6],"tickmode":"array","ticktext":["9:15am","9:30am","11:00am","11:18am","11:36am","11:54am","12:12pm","1:30pm","1:48pm","2:06pm","2:24pm","2:42pm","3:30pm","3:45pm","4:45pm","4:55pm","5:00pm","5:05pm","5:30pm","5:35pm","5:40pm","5:45pm","5:50pm","5:55pm","6:00pm","6:05pm","6:10pm","6:15pm","6:20pm"],"tickvals":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],"categoryorder":"array","categoryarray":["9:15am","9:30am","11:00am","11:18am","11:36am","11:54am","12:12pm","1:30pm","1:48pm","2:06pm","2:24pm","2:42pm","3:30pm","3:45pm","4:45pm","4:55pm","5:00pm","5:05pm","5:30pm","5:35pm","5:40pm","5:45pm","5:50pm","5:55pm","6:00pm","6:05pm","6:10pm","6:15pm","6:20pm"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.65296803652968,"tickwidth":0.66417600664176,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-45,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"y","title":"","titlefont":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-48.15,1011.15],"tickmode":"array","ticktext":["0","250","500","750","1000"],"tickvals":[0,250,500,750,1000],"categoryorder":"array","categoryarray":["0","250","500","750","1000"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.65296803652968,"tickwidth":0.66417600664176,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"x","title":"count","titlefont":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":"transparent","line":{"color":"rgba(51,51,51,1)","width":0.66417600664176,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":true,"legend":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"transparent","borderwidth":1.88976377952756,"font":{"color":"rgba(0,0,0,1)","family":"","size":11.689497716895},"y":0.943817833581613},"annotations":[{"text":"room","x":1.02,"y":1,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"left","yanchor":"bottom","legendTitle":true}],"hovermode":"closest","width":900,"height":555,"barmode":"relative"},"config":{"doubleClick":"reset","modeBarButtonsToAdd":[{"name":"Collaborate","icon":{"width":1000,"ascent":500,"descent":-50,"path":"M487 375c7-10 9-23 5-36l-79-259c-3-12-11-23-22-31-11-8-22-12-35-12l-263 0c-15 0-29 5-43 15-13 10-23 23-28 37-5 13-5 25-1 37 0 0 0 3 1 7 1 5 1 8 1 11 0 2 0 4-1 6 0 3-1 5-1 6 1 2 2 4 3 6 1 2 2 4 4 6 2 3 4 5 5 7 5 7 9 16 13 26 4 10 7 19 9 26 0 2 0 5 0 9-1 4-1 6 0 8 0 2 2 5 4 8 3 3 5 5 5 7 4 6 8 15 12 26 4 11 7 19 7 26 1 1 0 4 0 9-1 4-1 7 0 8 1 2 3 5 6 8 4 4 6 6 6 7 4 5 8 13 13 24 4 11 7 20 7 28 1 1 0 4 0 7-1 3-1 6-1 7 0 2 1 4 3 6 1 1 3 4 5 6 2 3 3 5 5 6 1 2 3 5 4 9 2 3 3 7 5 10 1 3 2 6 4 10 2 4 4 7 6 9 2 3 4 5 7 7 3 2 7 3 11 3 3 0 8 0 13-1l0-1c7 2 12 2 14 2l218 0c14 0 25-5 32-16 8-10 10-23 6-37l-79-259c-7-22-13-37-20-43-7-7-19-10-37-10l-248 0c-5 0-9-2-11-5-2-3-2-7 0-12 4-13 18-20 41-20l264 0c5 0 10 2 16 5 5 3 8 6 10 11l85 282c2 5 2 10 2 17 7-3 13-7 17-13z m-304 0c-1-3-1-5 0-7 1-1 3-2 6-2l174 0c2 0 4 1 7 2 2 2 4 4 5 7l6 18c0 3 0 5-1 7-1 1-3 2-6 2l-173 0c-3 0-5-1-8-2-2-2-4-4-4-7z m-24-73c-1-3-1-5 0-7 2-2 3-2 6-2l174 0c2 0 5 0 7 2 3 2 4 4 5 7l6 18c1 2 0 5-1 6-1 2-3 3-5 3l-174 0c-3 0-5-1-7-3-3-1-4-4-5-6z"},"click":"function(gd) { \n        // is this being viewed in RStudio?\n        if (location.search == '?viewer_pane=1') {\n          alert('To learn about plotly for collaboration, visit:\\n https://cpsievert.github.io/plotly_book/plot-ly-for-collaboration.html');\n        } else {\n          window.open('https://cpsievert.github.io/plotly_book/plot-ly-for-collaboration.html', '_blank');\n        }\n      }"}],"cloud":false},"source":"A","attrs":{"4b294fed220b":{"weight":{},"x":{},"fill":{},"text":{},"type":"bar"}},"cur_data":"4b294fed220b","visdat":{"4b294fed220b":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"base_url":"https://plot.ly"},"evals":["config.modeBarButtonsToAdd.0.click"],"jsHooks":[]}</script>
<div id="network-graph" class="section level3">
<h3>Network graph</h3>
<p>To make our-self a simple network graph will I be using the <a href="https://github.com/datastorm-open/visNetwork">visNetwork</a> package, which have a lovely vignette. So here first of all to create a manageable graph I’ll subset all the Wednesday talks in room 4.02, which was the “Shiny I” and “Text Mining” block.</p>
<pre class="r"><code>sub_data &lt;- left_join(events, people, by = &quot;id&quot;) %&gt;%
  filter(day == &quot;Wednesday&quot;, room == &quot;4.02&quot;) %&gt;%
  dplyr::select(name, attendee, time)</code></pre>
<p>I this graph I will let each node be a event and let the edges be to which degree they share attendees. So we start</p>
<pre class="r"><code>node_size &lt;- sub_data %&gt;% 
  group_by(name, time) %&gt;%
  summarize(n = n())</code></pre>
<p>to find how many attendees the events share with each other we first find all the different pairs of events with <code>utils::combn</code> function and with <code>purrr</code> and <code>inner_join</code> finds how many they have in common. Since <code>utils::combn</code> gives its result in a matrix we have to fiddle just a bit to our way back to a tibble.</p>
<pre class="r"><code>conn &lt;- combn(node_size$name, 2) %&gt;%
  as.tibble() %&gt;%
  map_int(~ inner_join(sub_data %&gt;% filter(name == .x[1]), 
                       sub_data %&gt;% filter(name == .x[2]), by = &quot;attendee&quot;)
              %&gt;% nrow()) %&gt;%
  rbind(combn(node_size$name, 2)) %&gt;% t() %&gt;% as.tibble()
names(conn) &lt;- c(&quot;n&quot;, &quot;from&quot;, &quot;to&quot;)
conn</code></pre>
<pre><code>## # A tibble: 45 x 3
##    n     from                              to                              
##    &lt;chr&gt; &lt;chr&gt;                             &lt;chr&gt;                           
##  1 21    A Tidy Data Model for Natural La… bradio: Add data music widgets …
##  2 58    A Tidy Data Model for Natural La… Developing and deploying large …
##  3 82    A Tidy Data Model for Natural La… How we built a Shiny App for 70…
##  4 84    A Tidy Data Model for Natural La… Interacting with databases from…
##  5 84    A Tidy Data Model for Natural La… manifestoR - a tool for data jo…
##  6 100   A Tidy Data Model for Natural La… Neural Embeddings and NLP with …
##  7 84    A Tidy Data Model for Natural La… ShinyProxy                      
##  8 156   A Tidy Data Model for Natural La… Text Analysis and Text Mining U…
##  9 169   A Tidy Data Model for Natural La… Text mining, the tidy way       
## 10 46    bradio: Add data music widgets t… Developing and deploying large …
## # ... with 35 more rows</code></pre>
<p>for the node tibble we need to supply it with a <em>id</em> column, but I will also supply it with a label (name of the event), size (number of people in the event) and color (what book is this event in. green = Shiny I, blue = Text Mining).</p>
<pre class="r"><code>Shiny_I &lt;- c(&quot;11:00am&quot;, &quot;11:18am&quot;, &quot;11:36am&quot;, &quot;11:54am&quot;, &quot;12:12pm&quot;)
Text_Mining &lt;- c(&quot;1:30pm&quot;, &quot;1:48pm&quot;, &quot;2:06pm&quot;, &quot;2:24pm&quot;, &quot;2:42pm&quot;)
nodes &lt;- node_size %&gt;% 
  mutate(id = name,
         label = str_wrap(name, width = 20),
         size = n / 20,
         color = case_when(
           time %in% Shiny_I ~ &quot;lightgreen&quot;,
           time %in% Text_Mining ~ &quot;lightblue&quot;
         ))</code></pre>
<p>for the edge tibble it needs <em>from</em> and <em>to</em> columns that matches with the <em>id</em> in the node tibble. I will also supply with a constant color column (because if omitted it would borrow from the node coloring) and a width column to indicate how many attendees they share. This is again done with a couple of left_joins and the connectivity is the average percentage of attendees they share. Lastly we remove any edge with less then 0.5 connectivity to clear out the graph.</p>
<pre class="r"><code>edges &lt;- conn %&gt;% 
  left_join(node_size %&gt;% 
              dplyr::select(-time) %&gt;% 
              rename(n_from = n), 
                   by = c(&quot;from&quot; = &quot;name&quot;)) %&gt;%
  left_join(node_size %&gt;% 
              dplyr::select(-time) %&gt;% 
              rename(n_to = n), 
                   by = c(&quot;to&quot; = &quot;name&quot;)) %&gt;%
  mutate(n = as.numeric(n),
         n_to = as.numeric(n_to),
         n_from = as.numeric(n_from),
         connectivity = (n / n_from + n / n_to) / 2,
         width = connectivity * 10,
         color = &quot;grey&quot;) %&gt;%
  filter(connectivity &gt; 0.5)</code></pre>
<p>Which yields us with the wonderful graph which show a somehow clear divide between the two blocks.</p>
<pre class="r"><code>visNetwork(nodes, edges, width = &quot;100%&quot;)</code></pre>
<div id="htmlwidget-2" style="width:100%;height:415.296px;" class="visNetwork html-widget"></div>
<script type="application/json" data-for="htmlwidget-2">{"x":{"nodes":{"name":["A Tidy Data Model for Natural Language Processing","bradio: Add data music widgets to your business intelligence dashboards","Developing and deploying large scale Shiny applications for non-life insurance","How we built a Shiny App for 700 users?","Interacting with databases from Shiny","manifestoR - a tool for data journalists, a source for text miners and a prototype for reproducibility software","Neural Embeddings and NLP with R and Spark","ShinyProxy","Text Analysis and Text Mining Using R","Text mining, the tidy way"],"time":["2:06pm","11:18am","12:12pm","11:00am","11:36am","1:48pm","2:42pm","11:54am","2:24pm","1:30pm"],"n":[210,73,193,308,295,138,200,291,252,330],"id":["A Tidy Data Model for Natural Language Processing","bradio: Add data music widgets to your business intelligence dashboards","Developing and deploying large scale Shiny applications for non-life insurance","How we built a Shiny App for 700 users?","Interacting with databases from Shiny","manifestoR - a tool for data journalists, a source for text miners and a prototype for reproducibility software","Neural Embeddings and NLP with R and Spark","ShinyProxy","Text Analysis and Text Mining Using R","Text mining, the tidy way"],"label":["A Tidy Data Model\nfor Natural Language\nProcessing","bradio: Add data\nmusic widgets\nto your business\nintelligence\ndashboards","Developing and\ndeploying large\nscale Shiny\napplications for\nnon-life insurance","How we built a Shiny\nApp for 700 users?","Interacting with\ndatabases from Shiny","manifestoR - a\ntool for data\njournalists, a\nsource for text\nminers and a\nprototype for\nreproducibility\nsoftware","Neural Embeddings\nand NLP with R and\nSpark","ShinyProxy","Text Analysis and\nText Mining Using R","Text mining, the\ntidy way"],"size":[10.5,3.65,9.65,15.4,14.75,6.9,10,14.55,12.6,16.5],"color":["lightblue","lightgreen","lightgreen","lightgreen","lightgreen","lightblue","lightblue","lightgreen","lightblue","lightblue"]},"edges":{"n":[84,156,169,61,145,138,148,213,202,204,110,189],"from":["A Tidy Data Model for Natural Language Processing","A Tidy Data Model for Natural Language Processing","A Tidy Data Model for Natural Language Processing","bradio: Add data music widgets to your business intelligence dashboards","Developing and deploying large scale Shiny applications for non-life insurance","Developing and deploying large scale Shiny applications for non-life insurance","Developing and deploying large scale Shiny applications for non-life insurance","How we built a Shiny App for 700 users?","How we built a Shiny App for 700 users?","Interacting with databases from Shiny","manifestoR - a tool for data journalists, a source for text miners and a prototype for reproducibility software","Text Analysis and Text Mining Using R"],"to":["manifestoR - a tool for data journalists, a source for text miners and a prototype for reproducibility software","Text Analysis and Text Mining Using R","Text mining, the tidy way","Interacting with databases from Shiny","How we built a Shiny App for 700 users?","Interacting with databases from Shiny","ShinyProxy","Interacting with databases from Shiny","ShinyProxy","ShinyProxy","Text mining, the tidy way","Text mining, the tidy way"],"n_from":[210,210,210,73,193,193,193,308,308,295,138,252],"n_to":[138,252,330,295,308,295,291,295,291,291,330,330],"connectivity":[0.504347826086956,0.680952380952381,0.658441558441558,0.521198049686557,0.611037278783393,0.591411258452621,0.637715221765219,0.706796169931763,0.675001115722765,0.696278175781933,0.565217391304348,0.661363636363636],"width":[5.04347826086956,6.80952380952381,6.58441558441558,5.21198049686557,6.11037278783393,5.91411258452621,6.37715221765219,7.06796169931763,6.75001115722765,6.96278175781933,5.65217391304348,6.61363636363636],"color":["grey","grey","grey","grey","grey","grey","grey","grey","grey","grey","grey","grey"]},"nodesToDataframe":true,"edgesToDataframe":true,"options":{"width":"100%","height":"100%","nodes":{"shape":"dot"},"manipulation":{"enabled":false}},"groups":null,"width":"100%","height":null,"idselection":{"enabled":false},"byselection":{"enabled":false},"main":null,"submain":null,"footer":null,"background":"rgba(0, 0, 0, 0)"},"evals":[],"jsHooks":[]}</script>
<p>I hope you enjoyed this post and I would love you see any and all visualization or analysis you might have regarding this data.</p>
</div>
</div>
