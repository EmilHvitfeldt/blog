---
title: Co Occurrence of Characters in Les Miserable
author: Emil Hvitfeldt
date: '2018-02-23'
slug: co-occurrence-of-characters-in-les-miserable
categories:
  - R
tags:
  - NLP
  - cleanNLP
  - tidyverse
  - ggplot2
---



<div id="what-are-we-doing" class="section level2">
<h2>What are we doing?</h2>
<p>The inspiration for this post is <a href="https://bost.ocks.org/mike/miserables/">this beutiful vizualization</a> from <a href="https://bost.ocks.org/mike/">Mike Bostock</a>. It nicely visualizes the co-occurrence of characters (when two characters appear in the same chapter) in the novel <a href="https://en.wikipedia.org/wiki/Les_Mis%C3%A9rables">Les Misérables</a> by <a href="https://en.wikipedia.org/wiki/Victor_Hugo">Victor Hugo</a> using the data collected by <a href="https://en.wikipedia.org/wiki/Jacques_Bertin">Jacques Bertin</a> (and his assistants).</p>
<p>The way this post will differentiate itself from this is that we are going to collect the data ourselves using <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition</a>. Named entity recognition is the discipline of location and classifying named entities in text. Furthermore will we also try to cluster the characters according to their appearance in the novel.</p>
<p>disclaimer! I have of the time of writing this analysis not read of familiarized myself with Les Misérables in a attempt to show how a blind text analysis would run.</p>
</div>
<div id="loading-package-and-backend" class="section level2">
<h2>Loading package and backend</h2>
<p>for this we will need <code>tidyverse</code> for general data science tasks, <code>cleanNLP</code> for the named entity recognition and <code>igraph</code> for some graph related transformation.</p>
<pre class="r"><code>library(tidyverse)
library(cleanNLP)
library(igraph)</code></pre>
<p>We will be using the <a href="https://spacy.io/">spacy</a> NLP back-end as the parser for this analysis since it provides named entity recognition as one of its functionalities. In <code>cleanNLP</code> we have to initialize the back-end using the <code>cnlp_init_spacy()</code> function that allows <code>cnlp_annotate()</code> to annotate the text.</p>
<pre class="r"><code>cnlp_init_spacy()</code></pre>
</div>
<div id="data" class="section level2">
<h2>Data</h2>
<p>Les Miserable is quite a long novel, in the terms of words and pages, however due to its age is it in the public domain and is easily available on <a href="https://www.gutenberg.org/">Project Gutenberg</a>.</p>
<pre class="r"><code>lesmis_raw &lt;- gutenbergr::gutenberg_download(135)</code></pre>
<p>Looking thought the beginning of the text we notice how a large part of the beginning of the document is table of content and other information that isn’t of interest in this analysis. Manually checking leads to be discard the first 650 lines of the data. We will also add a <code>chapter</code> column using a regex.</p>
<pre class="r"><code>lesmis_line &lt;- lesmis_raw %&gt;%
  slice(-(1:650)) %&gt;%
  mutate(chapter = cumsum(str_detect(text, &quot;CHAPTER &quot;)))</code></pre>
<p>For the use in <code>cnlp_annotate()</code> we need a data.frame where each row is a full chapter, with the 2 necessary columns <code>id</code> and <code>text</code>. This is accomplished using a simple <code>map</code>.</p>
<pre class="r"><code>lesmis &lt;- map_df(seq_len(max(lesmis_line$chapter)),
                 ~ tibble(id = .x,
                          text = lesmis_line %&gt;% 
                                   filter(chapter == .x) %&gt;% 
                                   pull(text) %&gt;% 
                                   paste(collapse = &quot; &quot;)))</code></pre>
<p>Now we are all ready to run the spacy parser which will only take a couple of minutes.</p>
<pre class="r"><code>lesmis_obj &lt;- cnlp_annotate(lesmis)</code></pre>
<p>the output we are given nothing more then a set of data.frames and a matrix which we can see the names for here</p>
<pre class="r"><code>names(lesmis_obj)</code></pre>
<pre><code>## [1] &quot;coreference&quot; &quot;dependency&quot;  &quot;document&quot;    &quot;entity&quot;      &quot;sentence&quot;   
## [6] &quot;token&quot;       &quot;vector&quot;</code></pre>
<p>It includes a lot of awesome information but we are only interested in the <code>entity</code> part of it for this time. This is done using the <code>cnlp_get_entity</code> (from the <code>cnlp_get_OBJECT</code> family).</p>
<pre class="r"><code>cnlp_get_entity(lesmis_obj) %&gt;%
  head()</code></pre>
<pre><code>## # A tibble: 6 x 6
##   id      sid   tid tid_end entity_type entity                            
##   &lt;chr&gt; &lt;int&gt; &lt;int&gt;   &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;                             
## 1 1         1     4       5 ORG         M. MYRIEL                         
## 2 1         2     2       2 DATE        1815                              
## 3 1         2     4      10 PERSON      M. Charles-François-Bienvenu Myri…
## 4 1         2    14      14 ORG         D----                             
## 5 1         3     7      11 CARDINAL    about seventy-five years          
## 6 1         3    21      21 ORG         D----</code></pre>
<p>We see quite a few different <code>entity_type</code>s, in fact lets take a quick look at the different types that are in this text</p>
<pre class="r"><code>cnlp_get_entity(lesmis_obj) %&gt;%
  pull(entity_type) %&gt;%
  unique()</code></pre>
<pre><code>##  [1] &quot;ORG&quot;         &quot;DATE&quot;        &quot;PERSON&quot;      &quot;CARDINAL&quot;    &quot;ORDINAL&quot;    
##  [6] &quot;EVENT&quot;       &quot;GPE&quot;         &quot;NORP&quot;        &quot;LOC&quot;         &quot;WORK_OF_ART&quot;
## [11] &quot;PRODUCT&quot;     &quot;FAC&quot;         &quot;TIME&quot;        &quot;LAW&quot;         &quot;MONEY&quot;      
## [16] &quot;LANGUAGE&quot;    &quot;QUANTITY&quot;    &quot;PERCENT&quot;</code></pre>
<p>for a full list of explanations see the documentation for <code>?cnlp_get_entity</code>. After a bit of investigating I have decided that we only will look at “PERSON” and “ORG” (which is due in part to Napoleon being classified as a organisation.) Furthermore I will limit further analysis to about the 50 most mentioned characters. The rational behind this is that it hopefully would capture most of the important characters, with the weight that characters that are mentioned sparingly but consistently is more important then characters with high density in a few chapter. We will include a few more characters in case we have to exclude some of them after looking.</p>
<pre class="r"><code>top_person_df &lt;- cnlp_get_entity(lesmis_obj) %&gt;%
  filter(entity_type %in% c(&quot;ORG&quot;, &quot;PERSON&quot;)) %&gt;%
  count(entity, sort = TRUE) %&gt;%
  slice(seq_len(60))

top_person_vec &lt;- top_person_df %&gt;% pull(entity)
top_person_vec</code></pre>
<pre><code>##  [1] &quot;Marius&quot;                    &quot;Jean Valjean&quot;             
##  [3] &quot;Cosette&quot;                   &quot;Javert&quot;                   
##  [5] &quot;Thénardier&quot;                &quot;Gavroche&quot;                 
##  [7] &quot;Bishop&quot;                    &quot;Fantine&quot;                  
##  [9] &quot; &quot;                         &quot;M. Madeleine&quot;             
## [11] &quot;Jondrette&quot;                 &quot;M. Gillenormand&quot;          
## [13] &quot;_&quot;                         &quot;Napoleon&quot;                 
## [15] &quot;Waterloo&quot;                  &quot;M. Leblanc&quot;               
## [17] &quot;Fauchelevent&quot;              &quot;Grantaire&quot;                
## [19] &quot;Madeleine&quot;                 &quot;Jean Valjean&#39;s&quot;           
## [21] &quot;Montparnasse&quot;              &quot;Éponine&quot;                  
## [23] &quot;Bossuet&quot;                   &quot;Brujon&quot;                   
## [25] &quot;D----&quot;                     &quot;Combeferre&quot;               
## [27] &quot;Monseigneur&quot;               &quot;M. Fauchelevent&quot;          
## [29] &quot;CHAPTER IV&quot;                &quot;Pontmercy&quot;                
## [31] &quot;Austerlitz&quot;                &quot;Champmathieu&quot;             
## [33] &quot;M. Mabeuf&quot;                 &quot;Monsieur&quot;                 
## [35] &quot;Joly&quot;                      &quot;Nicolette&quot;                
## [37] &quot;Voltaire&quot;                  &quot;Louis Philippe&quot;           
## [39] &quot;Mademoiselle Gillenormand&quot; &quot;Gillenormand&quot;             
## [41] &quot;Cæsar&quot;                     &quot;CHAPTER VI&quot;               
## [43] &quot;Lark&quot;                      &quot;Mayor&quot;                    
## [45] &quot;Théodule&quot;                  &quot;Magnon&quot;                   
## [47] &quot;Laigle&quot;                    &quot;Bahorel&quot;                  
## [49] &quot;Louis XVIII&quot;               &quot;Blachevelle&quot;              
## [51] &quot;Blücher&quot;                   &quot;Jean Prouvaire&quot;           
## [53] &quot;Mademoiselle Baptistine&quot;   &quot;Monsieur le Maire&quot;        
## [55] &quot;Bonaparte&quot;                 &quot;exclaimed:--&quot;             
## [57] &quot;Gorbeau&quot;                   &quot;Mabeuf&quot;                   
## [59] &quot;Madame Thénardier&quot;         &quot;Magloire&quot;</code></pre>
<p>After looking we see a few things we would like to fix before moving on. Firstly is “CHAPTER IV” and “CHAPTER VI” wrongly both classified as “ORG”s. &quot; “,”-&quot; and “exclaimed:–” and “Monsieur” have also been misclassified. “Jean Valjean’s” have been classified differently then “Jean Valjean” which is also the case with “Fauchelevent” and “M. Fauchelevent”, “M. Madeleine” and “Madeleine”, “M. Gillenormand”, “Gillenormand” and “Mademoiselle Gillenormand”. We will remove the miss-classifications here, and create a list of all the characters with all of their names. The list is named with the character’s main name for later subsetting.</p>
<pre class="r"><code>top_person_vec_clean &lt;- top_person_vec[-c(9, 13, 29, 34, 42, 56)] 

complications &lt;- list(c(&quot;Jean Valjean&quot;, &quot;Jean Valjean&#39;s&quot;),
                      c(&quot;Fauchelevent&quot;, &quot;M. Fauchelevent&quot;),
                      c(&quot;Madeleine&quot;, &quot;M. Madeleine&quot;),
                      c(&quot;Gillenormand&quot;, &quot;M. Gillenormand&quot;, &quot;Mademoiselle Gillenormand&quot;))

characters &lt;- setdiff(top_person_vec_clean, unlist(complications)) %&gt;%
  as.list() %&gt;%
  c(complications)

names(characters) &lt;- map_chr(characters, ~ .x[1])</code></pre>
<p>We expand the grid of all possible co occurrences and count how many times they both occur within a chapter.</p>
<pre class="r"><code>co_occurrence &lt;- expand.grid(map_chr(characters, ~ .x[1]), 
                             map_chr(characters, ~ .x[1])) %&gt;%
  set_names(c(&quot;person1&quot;, &quot;person2&quot;)) %&gt;%
  mutate(cooc = map2_dbl(person1, person2,
                         ~ sum(str_detect(lesmis$text, str_c(.x, collapse = &quot;|&quot;)) &amp; 
                               str_detect(lesmis$text, str_c(.y, collapse = &quot;|&quot;)))))</code></pre>
</div>
<div id="visualize" class="section level2">
<h2>Visualize</h2>
<p>now that we have the co occurrence data we can make some visualizations!! (I will take care of labels etc in the end. Hang on!)</p>
<pre class="r"><code>co_occurrence %&gt;%
  ggplot(aes(person1, person2, fill = cooc)) +
  geom_tile()</code></pre>
<p><img src="/post/2018-02-23-co-occurrence-of-characters-in-les-miserable_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>So at a first glance is it hard to see anything due to the default color-scale and the fact that a couple of people, Jean Valjean and Marius, appear in a much higher number of chapters (perhaps they are main characters?). To get a more manageable scale we disregard co occurrence if they have been in less then 5 chapters together(remember that there are a total of 365 chapters in novel).</p>
<pre class="r"><code>co_occurrence_1 &lt;- co_occurrence %&gt;%
  mutate(cooc = ifelse(cooc &gt; 5, log(cooc), NA))

co_occurrence_1 %&gt;%
    ggplot(aes(person1, person2, fill = cooc)) +
  geom_tile()</code></pre>
<p><img src="/post/2018-02-23-co-occurrence-of-characters-in-les-miserable_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>Now we finally see some of the fruit of our earlier work. It is definitely clear that there are groups of people that might form communities but it is unclear which and how many from this heat-map by itself. We would like to reorder the axis’s in the hope that it would create more clarity.</p>
<p>This data here can be seen as a <a href="https://en.wikipedia.org/wiki/Adjacency_matrix">Adjacency matrix</a> here the row numbers are vertices and the tiles-values are the edges connecting them. So in a sense we would like to do some cluster analysis on this graph. This can be done by doing some Spectral Graph Partitioning in which we calculate the eigenvectors and sort the vertices by the second smallest eigenvector.</p>
<pre class="r"><code>eigen &lt;- co_occurrence_1 %&gt;%
#  mutate(cooc = !is.na(cooc)) %&gt;%
  igraph::graph_from_data_frame() %&gt;%
  igraph::as_adj() %&gt;%
  eigen()

eigenvec2_sort &lt;- data.frame(eigen = eigen$vectors[, length(eigen$values) - 1]) %&gt;%
  mutate(row = row_number(),
         names = names(characters)) %&gt;%
  arrange(eigen)

eigen_names &lt;- eigenvec2_sort %&gt;% pull(names)</code></pre>
<p>We use sorted names to re-level the factors in the co occurrence data and see if it reveals more structure.</p>
<pre class="r"><code>co_occurrence_1 %&gt;%
  mutate(person1 = factor(person1, levels = eigen_names),
         person2 = factor(person2, levels = eigen_names)) %&gt;%
    ggplot(aes(person1, person2, fill = cooc)) +
  geom_tile()</code></pre>
<p><img src="/post/2018-02-23-co-occurrence-of-characters-in-les-miserable_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>it isn’t much but it appears to have moved the data slight closer to the diagonal. We will still need to locate some communities in this data. this can be done using the plotted eigenvector.</p>
<pre class="r"><code>eigenvec2_sort %&gt;% pull(eigen) %&gt;% plot(type = &quot;o&quot;)</code></pre>
<p><img src="/post/2018-02-23-co-occurrence-of-characters-in-les-miserable_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>And what we are looking at is not their position but at the jumps. There can more easily be seen when we look at the diffs</p>
<pre class="r"><code>eigenvec2_sort %&gt;% pull(eigen) %&gt;% diff() %&gt;% plot()
abline(h = 0.02)</code></pre>
<p><img src="/post/2018-02-23-co-occurrence-of-characters-in-les-miserable_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>And after playing around a little it seems that <code>0.02</code> is a appropriate cutoff.</p>
<pre class="r"><code>cummunity_df &lt;- eigenvec2_sort %&gt;%
  mutate(community = c(0, diff(eigen) &gt; 0.02) %&gt;% cumsum()) %&gt;%
  select(names, community)</code></pre>
<p>We will color-code the final visualization according to this clustering. So with a couple of joins</p>
<pre class="r"><code>co_occurrence_comm &lt;- co_occurrence_1 %&gt;%
  filter(!is.na(cooc)) %&gt;%
  mutate(person1_chr = as.character(person1),
         person2_chr = as.character(person2),
         person1 = factor(person1, levels = eigen_names),
         person2 = factor(person2, levels = eigen_names)) %&gt;%
  left_join(cummunity_df, by = c(&quot;person1_chr&quot; = &quot;names&quot;)) %&gt;%
  left_join(cummunity_df, by = c(&quot;person2_chr&quot; = &quot;names&quot;)) %&gt;%
  mutate(community = ifelse(community.x == community.y, community.x, NA),
         community = ifelse(!is.na(cooc), community, NA))</code></pre>
<p>With a couple of final touch-ups and we arrive at the final result:</p>
<pre class="r"><code>co_occurrence_comm %&gt;%
  ggplot(aes(person1, person2, alpha = cooc, fill = factor(community))) +
  geom_tile(color = &quot;grey50&quot;) +
  scale_alpha(range = c(0.5, 1)) +
  scale_fill_brewer(palette = &quot;Set1&quot;, na.value = &quot;grey50&quot;) +
  theme_minimal() + 
  theme(panel.grid.major = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1)) +
  guides(fill = &quot;none&quot;, alpha = &quot;none&quot;) +
  coord_fixed() +
  labs(x = NULL, y = NULL, 
       title = &quot;Les Misérables Co-occurrence&quot;, 
       subtitle = &quot;with color-coded communities&quot;)</code></pre>
<p><img src="/post/2018-02-23-co-occurrence-of-characters-in-les-miserable_files/figure-html/unnamed-chunk-22-1.png" width="768" /></p>
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<p>While I wasn’t able to find as full clusters as Jacques Bertin I still managed to get quite a lot of information out of the text regardless. I had fun in the progress and there are many more things I see myself doing with this new data set and <code>cleanNLP</code>.<br />
And while I couldn’t find a good way to include it in the main body of text. I almost finished the main analysis before realizing that <a href="https://en.wikipedia.org/wiki/Monsieur">Monsieur</a> means. Mention your mistakes in your posts so others can learn from them!</p>
</div>
